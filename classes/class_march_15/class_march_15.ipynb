{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72960a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/marco-canas/Machine-Learning/blob/main/ML/classes/class_mach_8/class_march_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91bc5e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# [Medidas de desempeño para un clasificador](https://www.knowledgeisle.com/wp-content/uploads/2019/12/2-Aur%C3%A9lien-G%C3%A9ron-Hands-On-Machine-Learning-with-Scikit-Learn-Keras-and-Tensorflow_-Concepts-Tools-and-Techniques-to-Build-Intelligent-Systems-O%E2%80%99Reilly-Media-2019.pdf) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50b6ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Medición de la exactitud mediante validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb1fe4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we\n",
    "will spend a large part of this chapter on this topic. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171ce3f4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many performance measures available, so grab another coffee and get ready to learn many new concepts and acronyms!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f695f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Measuring Accuracy Using Cross-Validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cd30c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A good way to evaluate a model is to use cross-validation, just as you did in Chapter 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdfb71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing Cross-Validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a772cc2a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Occasionally you will need more control over the cross-validation process than what Scikit-Learn provides off-the-shelf. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244886f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In these cases, you can implement cross- validation yourself; it is actually fairly straightforward. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b740ab1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The following code does roughly the same thing as Scikit-Learn’s `cross_val_score()` function, and prints the same result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45182db4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import fetch_openml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "813c36ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86e9142c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X,y = mnist['data'], mnist['target'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179e659a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Convertir a arreglos de numpy de valores enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3f2c53f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = X.values\n",
    "y = y.values.astype(np.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8f334e3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436f1e1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "    skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "    for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred)) # prints 0.9502, 0.96565 and 0.9649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83ca413",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9f4f2c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94df836d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4bb978d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiclass Classification  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c78f6f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Mientras que los clasificadores binarios distinguen entre dos clases, los clasificadores multiclase (también llamados clasificadores multinomiales) pueden distinguir entre más de dos clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a775ca7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algunos algoritmos (como los clasificadores SGD, los clasificadores Random Forest y los clasificadores Naive Bayes) son capaces de manejar varias clases de forma nativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f670bad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otros (como los clasificadores de regresión logística o de máquina de soporte vectorial) son clasificadores estrictamente binarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6ba8f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, existen varias estrategias que puede utilizar para realizar una clasificación multiclase con varios clasificadores binarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e117a2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Una forma de crear un sistema que pueda clasificar las imágenes de dígitos en 10 clases (del 0 al 9) es entrenar 10 clasificadores binarios, uno para cada dígito (un detector 0, un detector 1, un detector 2, etc.). en)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac18a71",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Luego, cuando desea clasificar una imagen, obtiene el puntaje de decisión de cada clasificador para esa imagen y selecciona la clase cuyo clasificador genera el puntaje más alto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f1c219",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto se denomina estrategia uno contra el resto (OvR) (también llamada uno contra todos)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2832d65c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Otra estrategia es entrenar un clasificador binario para cada par de dígitos: uno para distinguir 0s y 1s, otro para distinguir 0s y 2s, otro para 1s y 2s, y así sucesivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c73fa8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Esto se llama la estrategia uno contra uno (OvO)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198e943",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si hay N clases, necesita entrenar N × (N – 1) / 2 clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98514678",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para el problema MNIST, ¡esto significa entrenar 45 clasificadores binarios!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d6221",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando desee clasificar una imagen, debe ejecutar la imagen a través de los 45 clasificadores y ver qué clase gana la mayor cantidad de duelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f27a70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La principal ventaja de OvO es que cada clasificador solo necesita ser entrenado en la parte del conjunto de entrenamiento para las dos clases que debe distinguir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931adc2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Algunos algoritmos (como los clasificadores de máquinas de soporte vectorial) escalan mal con el tamaño del conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379258c7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Para estos algoritmos, se prefiere OvO porque es más rápido entrenar muchos clasificadores en pequeños conjuntos de entrenamiento que entrenar pocos clasificadores en grandes conjuntos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143c840c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Sin embargo, para la mayoría de los algoritmos de clasificación binaria, se prefiere OvR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6610d826",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Scikit-Learn detecta cuando intenta utilizar un algoritmo de clasificación binaria para una tarea de clasificación multiclase y automáticamente ejecuta OvR u OvO, según el algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849f731",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Intentemos esto con un clasificador de máquina de soporte vectorial, usando la clase sklearn.svm.SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883609cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml \n",
    "\n",
    "mnist = fetch_openml('mnist_784', version = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b486e3bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X,y = mnist['data'], mnist['target'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f04a1f42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "X = X.values\n",
    "y = y.values.ravel().astype(np.int64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ff9c58",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = X[:60_000,:], X[60_000:,:], y[:60_000], y[60_000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7ac7bd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14284/3777350274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msvm_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# y_train, not y_train_5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \"\"\"\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m             X = check_array(X, accept_sparse='csr', dtype=np.float64,\n\u001b[0m\u001b[0;32m    475\u001b[0m                             order=\"C\", accept_large_sparse=False)\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    714\u001b[0m                     \"into decimal numbers with dtype='numeric'\") from e\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[0;32m    717\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(X_train, y_train) # y_train, not y_train_5\n",
    "svm_clf.predict([X[:5,:]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76aa316",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "¡Eso fue fácil! Este código entrena el SVC en el conjunto de entrenamiento usando las clases de destino originales de 0 a 9 (y_train), en lugar de las clases de destino de 5 contra el resto (`y_train_5`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3025db",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Luego hace una predicción (una correcta en este caso)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cbbc5b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Debajo del capó, Scikit-Learn en realidad usó la estrategia OvO: entrenó a 45 clasificadores binarios, obtuvo sus puntajes de decisión para la imagen y seleccionó la clase que ganó la mayor cantidad de duelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939ceb55",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si llama al método `decision_function()`, verá que devuelve 10 puntuaciones por instancia (en lugar de solo 1). Esa es una puntuación por clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85cad57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f337bd3d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The highest score is indeed the one corresponding to class 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcae261a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc20b5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> svm_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4956cdab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> svm_clf.classes_[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141bd759",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ADVERTENCIA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d6df4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cuando se entrena un clasificador, almacena la lista de clases objetivo en su atributo `classes_`, ordenadas por valor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac0091",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "En este caso, el índice de cada clase en el arreglo `classes_` coincide convenientemente con la clase misma (por ejemplo, la clase en el índice 5 resulta ser la clase 5), pero en general no tendrá tanta suerte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad8838e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si desea forzar a Scikit-Learn a usar uno contra uno o uno contra el resto, puede usar las clases `OneVsOneClassifier` o `OneVsRestClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a219313",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simplemente cree una instancia y pase un clasificador a su constructor (ni siquiera tiene que ser un clasificador binario)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5b317",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Por ejemplo, este código crea un clasificador multiclase usando la estrategia OvR, basado en un SVC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a4a68",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC())\n",
    "ovr_clf.fit(X_train, y_train)\n",
    "ovr_clf.predict([X[0,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584be9d3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "len(ovr_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4afd244",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Training an SGDClassifier (or a RandomForestClassifier) is just as easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3612b08",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> sgd_clf.fit(X_train, y_train)\n",
    ">>> sgd_clf.predict([some_digit])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a100e6c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This time Scikit-Learn did not have to run OvR or OvO because SGD classifiers can directly classify instances into multiple classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41bbfef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The decision_function() method now returns one value per class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b3b2fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let’s look at the score that the SGD classifier assigned to each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c9215c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c295b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can see that the classifier is fairly confident about its prediction: almost all scores are largely negative, while class 5 has a score of 2412.5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ce5bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The model has a slight doubt regarding class 3, which gets a score of 573.5. Now of course you want to evaluate this classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f877a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As usual, you can use cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ab4e4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use the cross_val_score() function to evaluate the SGDClassifier’s accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d03dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836a9711",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It gets over 84% on all test folds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca13703",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you used a random classifier, you would get 10% accuracy, so this is not such a bad score, but you can still do much better. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bca0c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simply scaling the inputs (as discussed in Chapter 2) increases\n",
    "accuracy above 89%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc64fbdb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    ">>> scaler = StandardScaler()\n",
    ">>> X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    ">>> cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051a2c53",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9a5586",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If this were a real project, you would now follow the steps in your Machine Learning project checklist (see Appendix B). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf85fac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You’d explore data preparation options, try out multiple models (shortlisting the best ones and fine-tuning their hyperparameters using GridSearchCV), and automate as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cefc2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here, we will assume that you have found a promising model and you want to find ways to improve it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde005e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way to do this is to analyze the types of errors it makes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32ed2d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First, look at the confusion matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc453d78",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You need to make predictions using the cross_val_predict() function, then call the confusion_matrix() function, just like you did earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85df172f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    ">>> y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    ">>> conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    ">>> conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cd23df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed253c84",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c510321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "rise": {
   "enable_chalkboard": true,
   "theme": "sky",
   "transition": "zoom"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
